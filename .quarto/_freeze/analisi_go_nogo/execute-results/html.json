{
  "hash": "1bedf925af23476054b83c173fe7df57",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"HSAM: Analisi Go-NoGo\"\nauthor: \"Lorenzo Atzeni\"\nformat:\n  html:\n    toc: true\n    code: false  # Nasconde completamente il codice (senza freccette)\n    theme: flatly\n    self-contained: true\neditor: visual\n---\n\n\n\n\n\n\n### Pre-processing, data cleaning\n\nHo applicato una procedura simile a quella del dataframe del matching task, selezionando solo trial eseguiti correttamente (accuratezza=1) della condizione go. Inoltre ho escluso tempi di reazione estremi, definiti come valori oltre ±3 deviazioni standard dalla media per ciascun partecipante e condizione.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable:  trial per CNTRL (head) e HSAM (tail)\n\n|        | ID_CNTRL | other-first | self-first | ID_HSAM | other-first | self-first |\n|:-------|:--------:|:-----------:|:----------:|:-------:|:-----------:|:----------:|\n|CNTRL01 | CNTRL01  |     100     |    100     |  HM11   |     100     |    100     |\n|CNTRL02 | CNTRL02  |     100     |    100     |  HM12   |     100     |    100     |\n|CNTRL04 | CNTRL04  |     100     |    100     |  HM13   |     100     |    100     |\n|CNTRL05 | CNTRL05  |     100     |    100     |  HM14   |     100     |    100     |\n|CNTRL07 | CNTRL07  |     100     |    100     |  HM15   |     100     |    100     |\n|CNTRL08 | CNTRL08  |     100     |    100     |  HM16   |     100     |    100     |\n\n\n:::\n:::\n\n\n\n\nSelezioniamo solo trial corretti:\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable:  trial per CNTRL (head) e HSAM (tail)\n\n|        | ID_CNTRL | other-first | self-first | ID_HSAM | other-first | self-first |\n|:-------|:--------:|:-----------:|:----------:|:-------:|:-----------:|:----------:|\n|CNTRL01 | CNTRL01  |     50      |     49     |  HM11   |     50      |     50     |\n|CNTRL02 | CNTRL02  |     50      |     50     |  HM12   |     50      |     49     |\n|CNTRL04 | CNTRL04  |     50      |     50     |  HM13   |     49      |     50     |\n|CNTRL05 | CNTRL05  |     49      |     50     |  HM14   |     45      |     48     |\n|CNTRL07 | CNTRL07  |     46      |     48     |  HM15   |     50      |     49     |\n|CNTRL08 | CNTRL08  |     48      |     50     |  HM16   |     45      |     43     |\n\n\n:::\n:::\n\n\n\n\nCNTRL_13 deve essere escluso perchè ha sbagliato tutti i trial eccetto 1.\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n         \n          self-first\n  CNTRL13          1\n```\n\n\n:::\n:::\n\n\n\n\nEliminiamo adesso RT sotto e sopra 3 sd media ciascun partecipante e condizione:\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nSoggetto CNTRL01 - Blocco other-first : eliminati 1 outlier\nSoggetto CNTRL02 - Blocco self-first : eliminati 1 outlier\nSoggetto CNTRL04 - Blocco self-first : eliminati 1 outlier\nSoggetto CNTRL05 - Blocco self-first : eliminati 1 outlier\nSoggetto CNTRL07 - Blocco self-first : eliminati 1 outlier\nSoggetto CNTRL07 - Blocco other-first : eliminati 1 outlier\nSoggetto CNTRL08 - Blocco self-first : eliminati 1 outlier\nSoggetto CNTRL08 - Blocco other-first : eliminati 1 outlier\nSoggetto CNTRL10 - Blocco self-first : eliminati 1 outlier\nSoggetto CNTRL10 - Blocco other-first : eliminati 1 outlier\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTotale outlier eliminati:\n```\n\n\n:::\n:::\n\n\n\n\nMediamente è stata eliminata una osservazione per soggetto.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|Condizione  | Media_RT| SD_RT|\n|:-----------|--------:|-----:|\n|SCONOSCIUTO |    0.483| 0.114|\n|TU          |    0.472| 0.109|\n\n\n:::\n:::\n\n\n\n\nVisualizziamo gli RT delle due condizioni\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](analisi_go_nogo_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nAdesso fittiamo il modello:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nform<-bf(rt~ordine*group + (1+ordine|id_subj),\n         family = Gamma(link = \"log\"))\n\nmyPRIORS <- c(\n  set_prior(\"student_t(3, 0, 1)\", class = \"Intercept\"),\n  \n  set_prior( paste0(\"student_t(3, 0, .08)\"), class = \"b\", \n             coef = \"ordineTU\"),\n  set_prior( paste0(\"student_t(3, 0, .08)\"), class = \"b\", \n             coef = \"groupHSAM\"),\n  #set_prior( paste0(\"student_t(3, 0, .0055)\"), class = \"b\", \n  set_prior( paste0(\"student_t(3, 0, .08)\"), class = \"b\", \n             coef = \"ordineTU:groupHSAM\"),\n  set_prior( paste0(\"student_t(3, 0, 1)\"), class = \"sd\" ),\n  set_prior(paste0(\"gamma(17, 34)\"), class = \"shape\"))\n\n\nfit_bayes<- brm(\n  formula = form,\n  data = df_go_pulito,\n  prior = myPRIORS,\n  chains = 4,\n  cores = parallel::detectCores(),\n  iter = 4000,\n  warmup = 1000,\n  seed = 1,\n  control = list(adapt_delta = 0.99)\n)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gamma \n  Links: mu = log; shape = identity \nFormula: rt ~ ordine * group + (1 + ordine | id_subj) \n   Data: df_go_pulito (Number of observations: 2446) \n  Draws: 4 chains, each with iter = 4000; warmup = 1000; thin = 1;\n         total post-warmup draws = 12000\n\nMultilevel Hyperparameters:\n~id_subj (Number of levels: 27) \n                        Estimate Est.Error l-90% CI u-90% CI Rhat Bulk_ESS\nsd(Intercept)               0.16      0.03     0.12     0.20 1.00     4137\nsd(ordineTU)                0.06      0.02     0.04     0.09 1.00     5049\ncor(Intercept,ordineTU)    -0.19      0.24    -0.56     0.23 1.00     8827\n                        Tail_ESS\nsd(Intercept)               5272\nsd(ordineTU)                5929\ncor(Intercept,ordineTU)     7955\n\nRegression Coefficients:\n                   Estimate Est.Error l-90% CI u-90% CI Rhat Bulk_ESS Tail_ESS\nIntercept             -0.74      0.04    -0.81    -0.67 1.00     3969     5708\nordineTU              -0.04      0.02    -0.07    -0.01 1.00     9247     8168\ngroupHSAM              0.01      0.05    -0.07     0.09 1.00     4903     5779\nordineTU:groupHSAM     0.03      0.03    -0.01     0.08 1.00     9844     8799\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-90% CI u-90% CI Rhat Bulk_ESS Tail_ESS\nshape    17.75      0.51    16.92    18.60 1.00    18124     8474\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](analisi_go_nogo_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\nIl posterior predictive check mostra che il modello riesce a riprodurre bene i dati osservati. Osservando i parametri possiamo vedere che B1, ha una stima negativa pari a −0.04, con un intervallo di credibilità al 90% che va da −0.07 a −0.01. Data la posterior (figura in basso), è possibile calcolare la probabilità a posteriori che il parametro sia negativo o che sia postivo.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](analisi_go_nogo_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\nLa probabilità che sia negativo è di:\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.971\n```\n\n\n:::\n:::\n\n\n\n\nMentre la prob. a posteriori che sia positivo è di:\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.029\n```\n\n\n:::\n:::\n\n\n\n\nSulla base di queste informazioni possiamo dichiarare che date le nostre posterior, è estremamente più probabile che, i partecipanti rispondono più rapidamente nella condizione TU rispetto a quella SCONOSCIUTO.\n\nAnalogamente il parametro B3 di interazione, mostra una stima positiva di 0.03, ma l’intervallo di credibilità comprende lo zero (da −0.01 a 0.08). Andando a vedere la posterior (grafico sotto) si può poi calcolare la probabilità a posteriori che il parametro sia dentro l'intervallo nullo di +-10ms, e la probabilità che sia positivo o negativo.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](analisi_go_nogo_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\n\nLa probabilità che B3 sia negativo è di:\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.10875\n```\n\n\n:::\n:::\n\n\n\n\nMentre la prob. a posteriori che B3 sia positivo è di:\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.89125\n```\n\n\n:::\n:::\n\n\n\n\nL'intervallo nullo (NI) di B3 di+-10ms è compreso tra \\[-0.020 ; 0.020\\] e la prob a posteriori che il parametro caschi in tale intervallo è di:\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.27875\n```\n\n\n:::\n:::\n\n\n\n\nPer B3 avevamo scelto come prior una student_t(3, 0, .08). La prob. a priori che B3 si trovasse nel NI era di\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1812708\n```\n\n\n:::\n:::\n\n\n\n\nQuindi possiamo concludere che aggiornando le prior con i dati raccolti, la prob. che B3 cada nel NI è aumentata di\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.09747922\n```\n\n\n:::\n:::\n\n\n\n\nI dati hanno *aumentato* l'evidenza a favore dell'effetto nullo rispetto alla prior.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](analisi_go_nogo_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n\nHo fittato anche il modello frequentista per vedere eventuale convergenze/divergenze:\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: Gamma  ( log )\nFormula:          rt ~ ordine * group + (1 + ordine | id_subj)\nData: df_go_pulito\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n  -5262.7   -5216.2    2639.3   -5278.7      2438 \n\nRandom effects:\n\nConditional model:\n Groups  Name        Variance Std.Dev. Corr  \n id_subj (Intercept) 0.021341 0.14608        \n         ordineTU    0.004457 0.06676  -0.25 \nNumber of obs: 2446, groups:  id_subj, 27\n\nDispersion estimate for Gamma family (sigma^2): 0.0291 \n\nConditional model:\n                   Estimate Std. Error z value Pr(>|z|)    \n(Intercept)        -0.73956    0.04108 -18.001   <2e-16 ***\nordineTU           -0.04634    0.02085  -2.222   0.0263 *  \ngroupHSAM           0.01122    0.05717   0.196   0.8444    \nordineTU:groupHSAM  0.04476    0.02938   1.523   0.1277    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n",
    "supporting": [
      "analisi_go_nogo_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}