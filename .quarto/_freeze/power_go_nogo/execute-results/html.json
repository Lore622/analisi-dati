{
  "hash": "c733038de5b87db455c882b911af8d9f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"HSAM: Power Go-NoGo\"\nauthor: \"Lorenzo Atzeni\"\nformat:\n  html:\n    code: false  \n    theme: flatly\n    self-contained: true\neditor: visual\n---\n\n\n\n\n\n\nScegliamo i parametri:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nb0 <- -0.7  \nb1 <- 0.183   \nb2 <- 0      \nb3 <- 0.11\n```\n:::\n\n\n\n\nB0=-0.7 –\\> (exp(−0.7))= 500 ms (RT gruppo di controllo nella condizione SCONOSCIUTO)\n\nB1=0.183 -\\>(exp(0.183)) =1.2 incremento RT 20% stimoli associati al sè.\n\nB2--\\>nullo-\\> No differenze tra gruppi in RT nella condizione SCONOSCIUTO\n\nB3=0.11-\\>(exp(0.11)) -\\> 1.11-\\>per gli HSAM la condizione TU determina un aumento ulteriore dei tempi di reazione dell’11% rispetto a quanto osservato nei controlli, circa 55ms.\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\nInseriamo intercetta e slope random con r=.2\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\n# matrice di covarianza con correlazione 0.25\nSigma <- matrix(c(0.01, 0.0025,\n                  0.0025, 0.01), nrow = 2)\nrand_eff <- mvrnorm(n = N, mu = c(0, 0), Sigma = Sigma)\nb0i <- rand_eff[, 1]\nb1i <- rand_eff[, 2]\n\ndf$b0i <- b0i[df$id]\ndf$b1i <- b1i[df$id]\n```\n:::\n\n\n\n\nCalcoliamo rate usando la formula inversa shape=mu/rate\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshape=17\nlog_mu <- with(df, b0 + b1*I + b2*G + b3*I*G +b0i + b1i * I)\nmu <- exp(log_mu)\nrate<-shape/mu\n\ndf$y  <- rgamma(nrow(df), shape = shape, scale = mu / shape)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.1910  0.4485  0.5478  0.5748  0.6726  1.4918 \n```\n\n\n:::\n\n::: {.cell-output-display}\n![](power_go_nogo_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n\nFacciamo una prova e fittiamo il modello con n=10000 per vedere se stima bene i parametri.\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: Gamma  ( log )\nFormula:          y ~ I * G + (1 + I | id)\nData: df\n\n       AIC        BIC     logLik  -2*log(L)   df.resid \n-1147348.5 -1147254.0   573682.2 -1147364.5     999992 \n\nRandom effects:\n\nConditional model:\n Groups Name        Variance Std.Dev. Corr \n id     (Intercept) 0.009881 0.09940       \n        I           0.009863 0.09931  0.23 \nNumber of obs: 1000000, groups:  id, 10000\n\nDispersion estimate for Gamma family (sigma^2): 0.059 \n\nConditional model:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -0.701234   0.001487  -471.5   <2e-16 ***\nI            0.184172   0.001564   117.8   <2e-16 ***\nG            0.001298   0.002103     0.6    0.537    \nI:G          0.112797   0.002211    51.0   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\nCon `n = 10000` il modello riesce a stimare correttamente i parametri. Passiamo ora alla scelta delle prior.\n\nPoiché in letteratura esiste un solo studio simile al nostro (*Dalmaso et al., 2019*), è opportuno adottare **prior scettiche**, cioè centrate sullo zero e con varianza ridotta, come suggerito da *Kruschke e Liddell (2018)*. Tuttavia, con campioni più piccoli, questo approccio rischia di spingere la stima di β₃ costantemente verso lo zero, limitando l’inferenza.\n\nPer ovviare a questo problema, come già fatto nell'articolo preparato per il GIP, è stata scelta una **distribuzione t di Student con 3 gradi di libertà**, media zero e deviazione standard pari a **0.08**. Questa specifica consente di rappresentare un’ampia gamma di valori plausibili per l’effetto, pur mantenendo una maggiore densità in prossimità dello zero.\n\nIn particolare, questa prior **ammette che l’interazione tra identità e gruppo possa produrre una variazione del tempo di reazione compresa tra circa −30% e +40%**, ma conserva un atteggiamento cauto rispetto all'evidenza. Include comodamente anche il valore simulato come reale, che corrisponde a un effetto del **+11%**. In questo modo, si ottiene una stima credibile che incorpora l’incertezza iniziale **senza compromettere l’identificabilità del modello**.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(brms)\n\n#priorB3<-a prior ammette che l’effetto differenziale possa andare da circa –30 % a +40 %, con maggior densità vicino a 0. \n#Contiene comodamente il valore vero simulato (+11 %).\n  myPRIORS <- c(\n    set_prior(\"student_t(3, 0, 1)\", class = \"Intercept\"),\n    \n  set_prior( paste0(\"student_t(3, 0, .08)\"), class = \"b\", \n             coef = \"I\"),\n  set_prior( paste0(\"student_t(3, 0, .08)\"), class = \"b\", \n             coef = \"G\"),\n  #set_prior( paste0(\"student_t(3, 0, .0055)\"), class = \"b\", \n  set_prior( paste0(\"student_t(3, 0, .08)\"), class = \"b\", \n             coef = \"I:G\"),\n  set_prior( paste0(\"student_t(3, 0, 1)\"), class = \"sd\" ),\n  set_prior(paste0(\"gamma(\", shape, \", 17)\"), class = \"shape\"))\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](power_go_nogo_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\nla probabilità che B3 cada nell intervallo nullo è di:\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1795297\n```\n\n\n:::\n:::\n\n\n\n\nmentre che sia maggiore uguale a .11 è di:\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.131413\n```\n\n\n:::\n:::\n\n\n\n\n**Algoritmo calcolo power:** La potenza viene calcolata come il rapporto tra il numero di volte in cui l'intervallo di credibilità del parametro b3 non include lo zero sul totale numero di iterazioni.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nBE <- c(-0.7, 0.183, 0, 0.11)\n\nLEVEL <- .90\n\nPROBS <- c((1 - LEVEL) / 2, 1 - (1 - LEVEL) / 2)\n\n#sample_size <- c(20, 50, 70, 100, 120, 150)\nsample_size <- c(20, 50, 70, 100, 120)\nn_sim <- 100\nn_trial <- 100\nshape <- 17\nSigma <- matrix(c(0.01, 0.0025, 0.0025, 0.01), 2, 2)\nSCENARIO <- \"go_no_go\"\ndatadir <- \"./\"  # o dove vuoi salvare i file\nLETTER <- \"A\"\n\nform <- bf(y ~ I * G + (1 + I | id), family = Gamma(link = \"log\"))\nEXP2_all <- NULL  \n\n# Funzione per simulare i dati\nfor (n in sample_size) {\n  EXP2 <- OBS <- NULL\n  for (b in 1:n_sim) {\n    cat(paste0(\"n = \", n, \" (\", b, \"/\", n_sim, \")\\n\"))\n    \n    df <- expand.grid(trial = 1:n_trial, id = 1:n)\n    df$G <- ifelse(df$id <= n / 2, 0, 1)\n    df$I <- ifelse(df$trial <= (n_trial / 2), 0, 1)\n    \n    rand_eff <- mvrnorm(n = n, mu = c(0, 0), Sigma = Sigma)\n    b0i <- rand_eff[, 1]\n    b1i <- rand_eff[, 2]\n    \n    df$b0i <- b0i[df$id]\n    df$b1i <- b1i[df$id]\n    \n    log_mu <- with(df, BE[1] + BE[2]*I + BE[3]*G + BE[4]*I*G + b0i + b1i * I)\n    mu <- exp(log_mu)\n    df$y <- rgamma(nrow(df), shape = shape, scale = mu / shape)\n    \n    if (b == 1) {\n      base_fit <- brm(formula = form, data = df, prior = myPRIORS,\n                      chains = 4, iter = 4000, warmup = 1000,\n                      control = list(adapt_delta = 0.99),\n                      cores = parallel::detectCores(), refresh = 0)\n    }\n    \n    fit <- update(base_fit, newdata = df, recompile = FALSE, refresh = 0)\n    \n    converged <- all(rhat(fit) <= 1.05)\n    \n    est <- data.frame(fixef(fit, probs = PROBS))\n    \n    est$detected <- FALSE  # inizializza tutta la colonna\n    ci_b3 <- est[\"I:G\", c(\"Q5\", \"Q95\")]  #CI_low, CI_high\n    est[\"I:G\", \"detected\"] <- (ci_b3[1] > 0 | ci_b3[2] < 0) #CI_low>0  CI_high<0\n    est$converged <- converged\n    est$par <- rownames(est)\n    est$n <- n\n    est$iter <- b\n    est$scenario <- SCENARIO\n    \n    EXP2 <- rbind(EXP2, est)\n  }\n  \n  save(EXP2, file = paste0(datadir, \"power_sim_\", SCENARIO, \"_n\", n, LETTER, \".rda\"))\n   EXP2_all <- rbind(EXP2_all, EXP2)  \n}\n\n\nEXP2_b3 <- subset(EXP2_all, par == \"I:G\"& converged == TRUE)\npower_by_n <- aggregate(detected ~ n, data = EXP2_b3, FUN = mean)\nprint(power_by_n)\n\nsave(EXP2_all, file = paste0(datadir, \"power_sim_\", SCENARIO, \"_ALL\", LETTER, \".rda\"))\n```\n:::\n\n\n\n\nPer verificare il funzionamento dell’algoritmo, ho eseguito un test locale sul mio PC riducendo il numero di iterazioni a 10 per ciascuna numerosità campionaria e abbassando il numero di trial da 100 a 30.\\\n\n![Stima preliminare della potenza](power_b3.png)\n\nSebbene i risultati ottenuti non siano statisticamente affidabili, sembrano indicare che il codice gira correttamente. Possiamo quindi procedere con l’implementazione su SLURM per l’analisi completa.\n\n::: {style=\"text-align: left; margin-top: 2em;\"}\n<a href=\"analisi_go_nogo.html\" class=\"btn btn-outline-secondary\">← Go/No-Go</a>\n:::\n",
    "supporting": [
      "power_go_nogo_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}