[
  {
    "objectID": "power_go_nogo.html",
    "href": "power_go_nogo.html",
    "title": "HSAM: Power Go-NoGo",
    "section": "",
    "text": "Scegliamo i parametri:\n\nb0 &lt;- -0.7  \nb1 &lt;- 0.183   \nb2 &lt;- 0      \nb3 &lt;- 0.11\n\nB0=-0.7 –&gt; (exp(−0.7))= 500 ms (RT gruppo di controllo nella condizione SCONOSCIUTO)\nB1=0.183 -&gt;(exp(0.183)) =1.2 incremento RT 20% stimoli associati al sè.\nB2–&gt;nullo-&gt; No differenze tra gruppi in RT nella condizione SCONOSCIUTO\nB3=0.11-&gt;(exp(0.11)) -&gt; 1.11-&gt;per gli HSAM la condizione TU determina un aumento ulteriore dei tempi di reazione dell’11% rispetto a quanto osservato nei controlli, circa 55ms.\nInseriamo intercetta e slope random con r=.2\n\nlibrary(MASS)\n# matrice di covarianza con correlazione 0.25\nSigma &lt;- matrix(c(0.01, 0.0025,\n                  0.0025, 0.01), nrow = 2)\nrand_eff &lt;- mvrnorm(n = N, mu = c(0, 0), Sigma = Sigma)\nb0i &lt;- rand_eff[, 1]\nb1i &lt;- rand_eff[, 2]\n\ndf$b0i &lt;- b0i[df$id]\ndf$b1i &lt;- b1i[df$id]\n\nCalcoliamo rate usando la formula inversa shape=mu/rate\n\nshape=17\nlog_mu &lt;- with(df, b0 + b1*I + b2*G + b3*I*G +b0i + b1i * I)\nmu &lt;- exp(log_mu)\nrate&lt;-mu/shape\n\ndf$y  &lt;- rgamma(nrow(df), shape = shape, scale = mu / shape)\n\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.1373  0.4446  0.5445  0.5679  0.6666  1.6172 \n\n\n\n\n\n\n\n\n\nFacciamo una prova e fittiamo il modello con n=10000 per vedere se stima bene i parametri.\n\n\n Family: Gamma  ( log )\nFormula:          y ~ I * G + (1 + I | id)\nData: df\n\n       AIC        BIC     logLik  -2*log(L)   df.resid \n-1147348.5 -1147254.0   573682.2 -1147364.5     999992 \n\nRandom effects:\n\nConditional model:\n Groups Name        Variance Std.Dev. Corr \n id     (Intercept) 0.009881 0.09940       \n        I           0.009863 0.09931  0.23 \nNumber of obs: 1000000, groups:  id, 10000\n\nDispersion estimate for Gamma family (sigma^2): 0.059 \n\nConditional model:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.701234   0.001487  -471.5   &lt;2e-16 ***\nI            0.184172   0.001564   117.8   &lt;2e-16 ***\nG            0.001298   0.002103     0.6    0.537    \nI:G          0.112797   0.002211    51.0   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCon n = 10000 il modello riesce a stimare correttamente i parametri. Passiamo ora alla scelta delle prior.\nPoiché in letteratura esiste un solo studio simile al nostro (Dalmaso et al., 2019), è opportuno adottare prior scettiche, cioè centrate sullo zero e con varianza ridotta, come suggerito da Kruschke e Liddell (2018). Tuttavia, con campioni più piccoli, questo approccio rischia di spingere la stima di β₃ costantemente verso lo zero, limitando l’inferenza.\nPer ovviare a questo problema, come già fatto nell’articolo preparato per il GIP, è stata scelta una distribuzione t di Student con 3 gradi di libertà, media zero e deviazione standard pari a 0.08. Questa specifica consente di rappresentare un’ampia gamma di valori plausibili per l’effetto, pur mantenendo una maggiore densità in prossimità dello zero.\nIn particolare, questa prior ammette che l’interazione tra identità e gruppo possa produrre una variazione del tempo di reazione compresa tra circa −30% e +40%, ma conserva un atteggiamento cauto rispetto all’evidenza. Include comodamente anche il valore simulato come reale, che corrisponde a un effetto del +11%. In questo modo, si ottiene una stima credibile che incorpora l’incertezza iniziale senza compromettere l’identificabilità del modello.\n\nlibrary(brms)\n\n#priorB3&lt;-a prior ammette che l’effetto differenziale possa andare da circa –30 % a +40 %, con maggior densità vicino a 0. \n#Contiene comodamente il valore vero simulato (+11 %).\n  myPRIORS &lt;- c(\n    set_prior(\"student_t(3, 0, 1)\", class = \"Intercept\"),\n    \n  set_prior( paste0(\"student_t(3, 0, .08)\"), class = \"b\", \n             coef = \"I\"),\n  set_prior( paste0(\"student_t(3, 0, .08)\"), class = \"b\", \n             coef = \"G\"),\n  #set_prior( paste0(\"student_t(3, 0, .0055)\"), class = \"b\", \n  set_prior( paste0(\"student_t(3, 0, .08)\"), class = \"b\", \n             coef = \"I:G\"),\n  set_prior( paste0(\"student_t(3, 0, 1)\"), class = \"sd\" ),\n  set_prior(paste0(\"gamma(\", shape, \", 34)\"), class = \"shape\"))\n\n\n\n\n\n\n\n\n\n\nla probabilità che B3 cada nell intervallo nullo è di:\n\n\n[1] 0.1795297\n\n\nmentre che sia maggiore uguale a .11 è di:\n\n\n[1] 0.131413\n\n\nAlgoritmo calcolo power: La potenza viene calcolata come il rapporto tra il numero di volte in cui l’intervallo di credibilità del parametro b3 non include lo zero sul totale numero di iterazioni.\n\nBE &lt;- c(-0.7, 0.183, 0, 0.11)\n\nLEVEL &lt;- .90\n\nPROBS &lt;- c((1 - LEVEL) / 2, 1 - (1 - LEVEL) / 2)\n\n#sample_size &lt;- c(20, 50, 70, 100, 120, 150)\nsample_size &lt;- c(20, 50, 70, 100, 120)\nn_sim &lt;- 100\nn_trial &lt;- 100\nshape &lt;- 17\nSigma &lt;- matrix(c(0.01, 0.0025, 0.0025, 0.01), 2, 2)\nSCENARIO &lt;- \"go_no_go\"\ndatadir &lt;- \"./\"  # o dove vuoi salvare i file\nLETTER &lt;- \"A\"\n\nform &lt;- bf(y ~ I * G + (1 + I | id), family = Gamma(link = \"log\"))\n\n\n# Funzione per simulare i dati\nfor (n in sample_size) {\n  EXP2 &lt;- OBS &lt;- NULL\n  for (b in 1:n_sim) {\n    cat(paste0(\"n = \", n, \" (\", b, \"/\", n_sim, \")\\n\"))\n    \n    df &lt;- expand.grid(trial = 1:n_trial, id = 1:n)\n    df$G &lt;- ifelse(df$id &lt;= n / 2, 0, 1)\n    df$I &lt;- ifelse(df$trial &lt;= (n_trial / 2), 0, 1)\n    \n    rand_eff &lt;- mvrnorm(n = n, mu = c(0, 0), Sigma = Sigma)\n    b0i &lt;- rand_eff[, 1]\n    b1i &lt;- rand_eff[, 2]\n    \n    df$b0i &lt;- b0i[df$id]\n    df$b1i &lt;- b1i[df$id]\n    \n    log_mu &lt;- with(df, BE[1] + BE[2]*I + BE[3]*G + BE[4]*I*G + b0i + b1i * I)\n    mu &lt;- exp(log_mu)\n    df$y &lt;- rgamma(nrow(df), shape = shape, scale = mu / shape)\n    \n    if (b == 1) {\n      base_fit &lt;- brm(formula = form, data = df, prior = myPRIORS,\n                      chains = 4, iter = 4000, warmup = 1000,\n                      control = list(adapt_delta = 0.99),\n                      cores = parallel::detectCores(), refresh = 0)\n    }\n    \n    fit &lt;- update(base_fit, newdata = df, recompile = FALSE, refresh = 0)\n    \n    converged &lt;- all(rhat(fit) &lt;= 1.05)\n    \n    est &lt;- data.frame(fixef(fit, probs = PROBS))\n    \n    est$detected &lt;- FALSE  # inizializza tutta la colonna\n    ci_b3 &lt;- est[\"I:G\", c(\"Q5\", \"Q95\")]  #CI_low, CI_high\n    est[\"I:G\", \"detected\"] &lt;- (ci_b3[1] &gt; 0 | ci_b3[2] &lt; 0) #CI_low&gt;0  CI_high&lt;0\n    est$converged &lt;- converged\n    est$par &lt;- rownames(est)\n    est$n &lt;- n\n    est$iter &lt;- b\n    est$scenario &lt;- SCENARIO\n    \n    EXP2 &lt;- rbind(EXP2, est)\n  }\n  \n  save(EXP2, file = paste0(datadir, \"power_sim_\", SCENARIO, \"_n\", n, LETTER, \".rda\"))\n}\n\n\nEXP2_b3 &lt;- subset(EXP2, par == \"I:G\"& converged == TRUE)\npower_by_n &lt;- aggregate(detected ~ n, data = EXP2_b3, FUN = mean)\nprint(power_by_n)"
  },
  {
    "objectID": "analisi_go_nogo.html",
    "href": "analisi_go_nogo.html",
    "title": "HSAM: Analisi Go-NoGo",
    "section": "",
    "text": "Pre-processing, data cleaning\nHo applicato una procedura simile a quella del dataframe del matching task, selezionando solo trial eseguiti correttamente (accuratezza=1) della condizione go. Inoltre ho escluso tempi di reazione estremi, definiti come valori oltre ±3 deviazioni standard dalla media per ciascun partecipante e condizione.\n\n\n\ntrial per CNTRL (head) e HSAM (tail)\n\n\n\n\n\n\n\n\n\n\n\n\nID_CNTRL\nother-first\nself-first\nID_HSAM\nother-first\nself-first\n\n\n\n\nCNTRL01\nCNTRL01\n100\n100\nHM11\n100\n100\n\n\nCNTRL02\nCNTRL02\n100\n100\nHM12\n100\n100\n\n\nCNTRL04\nCNTRL04\n100\n100\nHM13\n100\n100\n\n\nCNTRL05\nCNTRL05\n100\n100\nHM14\n100\n100\n\n\nCNTRL07\nCNTRL07\n100\n100\nHM15\n100\n100\n\n\nCNTRL08\nCNTRL08\n100\n100\nHM16\n100\n100\n\n\n\n\n\nSelezioniamo solo trial corretti:\n\n\n\ntrial per CNTRL (head) e HSAM (tail)\n\n\n\n\n\n\n\n\n\n\n\n\nID_CNTRL\nother-first\nself-first\nID_HSAM\nother-first\nself-first\n\n\n\n\nCNTRL01\nCNTRL01\n50\n49\nHM11\n50\n50\n\n\nCNTRL02\nCNTRL02\n50\n50\nHM12\n50\n49\n\n\nCNTRL04\nCNTRL04\n50\n50\nHM13\n49\n50\n\n\nCNTRL05\nCNTRL05\n49\n50\nHM14\n45\n48\n\n\nCNTRL07\nCNTRL07\n46\n48\nHM15\n50\n49\n\n\nCNTRL08\nCNTRL08\n48\n50\nHM16\n45\n43\n\n\n\n\n\nCNTRL_13 deve essere escluso perchè ha sbagliato tutti i trial eccetto 1.\n\n\n         \n          self-first\n  CNTRL13          1\n\n\nEliminiamo adesso RT sotto e sopra 3 sd media ciascun partecipante e condizione:\n\n\nSoggetto CNTRL01 - Blocco other-first : eliminati 1 outlier\nSoggetto CNTRL02 - Blocco self-first : eliminati 1 outlier\nSoggetto CNTRL04 - Blocco self-first : eliminati 1 outlier\nSoggetto CNTRL05 - Blocco self-first : eliminati 1 outlier\nSoggetto CNTRL07 - Blocco self-first : eliminati 1 outlier\nSoggetto CNTRL07 - Blocco other-first : eliminati 1 outlier\nSoggetto CNTRL08 - Blocco self-first : eliminati 1 outlier\nSoggetto CNTRL08 - Blocco other-first : eliminati 1 outlier\nSoggetto CNTRL10 - Blocco self-first : eliminati 1 outlier\nSoggetto CNTRL10 - Blocco other-first : eliminati 1 outlier\n\n\nTotale outlier eliminati:\n\n\nMediamente è stata eliminata una osservazione per soggetto.\n\n\n\n\n\nCondizione\nMedia_RT\nSD_RT\n\n\n\n\nSCONOSCIUTO\n0.483\n0.114\n\n\nTU\n0.472\n0.109\n\n\n\n\n\nVisualizziamo gli RT delle due condizioni\n\n\n\n\n\n\n\n\n\nAdesso fittiamo il modello:\n\nform&lt;-bf(rt~ordine*group + (1+ordine|id_subj),\n         family = Gamma(link = \"log\"))\n\nmyPRIORS &lt;- c(\n  set_prior(\"student_t(3, 0, 1)\", class = \"Intercept\"),\n  \n  set_prior( paste0(\"student_t(3, 0, .08)\"), class = \"b\", \n             coef = \"ordineTU\"),\n  set_prior( paste0(\"student_t(3, 0, .08)\"), class = \"b\", \n             coef = \"groupHSAM\"),\n  #set_prior( paste0(\"student_t(3, 0, .0055)\"), class = \"b\", \n  set_prior( paste0(\"student_t(3, 0, .08)\"), class = \"b\", \n             coef = \"ordineTU:groupHSAM\"),\n  set_prior( paste0(\"student_t(3, 0, 1)\"), class = \"sd\" ),\n  set_prior(paste0(\"gamma(17, 34)\"), class = \"shape\"))\n\n\nfit_bayes&lt;- brm(\n  formula = form,\n  data = df_go_pulito,\n  prior = myPRIORS,\n  chains = 4,\n  cores = parallel::detectCores(),\n  iter = 4000,\n  warmup = 1000,\n  seed = 1,\n  control = list(adapt_delta = 0.99)\n)\n\n\n\n Family: gamma \n  Links: mu = log; shape = identity \nFormula: rt ~ ordine * group + (1 + ordine | id_subj) \n   Data: df_go_pulito (Number of observations: 2446) \n  Draws: 4 chains, each with iter = 4000; warmup = 1000; thin = 1;\n         total post-warmup draws = 12000\n\nMultilevel Hyperparameters:\n~id_subj (Number of levels: 27) \n                        Estimate Est.Error l-90% CI u-90% CI Rhat Bulk_ESS\nsd(Intercept)               0.16      0.03     0.12     0.20 1.00     4137\nsd(ordineTU)                0.06      0.02     0.04     0.09 1.00     5049\ncor(Intercept,ordineTU)    -0.19      0.24    -0.56     0.23 1.00     8827\n                        Tail_ESS\nsd(Intercept)               5272\nsd(ordineTU)                5929\ncor(Intercept,ordineTU)     7955\n\nRegression Coefficients:\n                   Estimate Est.Error l-90% CI u-90% CI Rhat Bulk_ESS Tail_ESS\nIntercept             -0.74      0.04    -0.81    -0.67 1.00     3969     5708\nordineTU              -0.04      0.02    -0.07    -0.01 1.00     9247     8168\ngroupHSAM              0.01      0.05    -0.07     0.09 1.00     4903     5779\nordineTU:groupHSAM     0.03      0.03    -0.01     0.08 1.00     9844     8799\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-90% CI u-90% CI Rhat Bulk_ESS Tail_ESS\nshape    17.75      0.51    16.92    18.60 1.00    18124     8474\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n\n\n\n\n\n\nIl posterior predictive check mostra che il modello riesce a riprodurre bene i dati osservati. Osservando i parametri possiamo vedere che B1, ha una stima negativa pari a −0.04, con un intervallo di credibilità al 90% che va da −0.07 a −0.01. Data la posterior (figura in basso), è possibile calcolare la probabilità a posteriori che il parametro sia negativo o che sia postivo.\n\n\n\n\n\n\n\n\n\nLa probabilità che sia negativo è di:\n\n\n[1] 0.971\n\n\nMentre la prob. a posteriori che sia positivo è di:\n\n\n[1] 0.029\n\n\nSulla base di queste informazioni possiamo dichiarare che date le nostre posterior, è estremamente più probabile che, i partecipanti rispondono più rapidamente nella condizione TU rispetto a quella SCONOSCIUTO.\nAnalogamente il parametro B3 di interazione, mostra una stima positiva di 0.03, ma l’intervallo di credibilità comprende lo zero (da −0.01 a 0.08). Andando a vedere la posterior (grafico sotto) si può poi calcolare la probabilità a posteriori che il parametro sia dentro l’intervallo nullo di +-10ms, e la probabilità che sia positivo o negativo.\n\n\n\n\n\n\n\n\n\nLa probabilità che B3 sia negativo è di:\n\n\n[1] 0.10875\n\n\nMentre la prob. a posteriori che B3 sia positivo è di:\n\n\n[1] 0.89125\n\n\nL’intervallo nullo (NI) di B3 di+-10ms è compreso tra [-0.020 ; 0.020] e la prob a posteriori che il parametro caschi in tale intervallo è di:\n\n\n[1] 0.27875\n\n\nPer B3 avevamo scelto come prior una student_t(3, 0, .08). La prob. a priori che B3 si trovasse nel NI era di\n\n\n[1] 0.1812708\n\n\nQuindi possiamo concludere che aggiornando le prior con i dati raccolti, la prob. che B3 cada nel NI è aumentata di\n\n\n[1] 0.09747922\n\n\nI dati hanno aumentato l’evidenza a favore dell’effetto nullo rispetto alla prior.\n\n\n\n\n\n\n\n\n\nHo fittato anche il modello frequentista per vedere eventuale convergenze/divergenze:\n\n\n Family: Gamma  ( log )\nFormula:          rt ~ ordine * group + (1 + ordine | id_subj)\nData: df_go_pulito\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n  -5262.7   -5216.2    2639.3   -5278.7      2438 \n\nRandom effects:\n\nConditional model:\n Groups  Name        Variance Std.Dev. Corr  \n id_subj (Intercept) 0.021341 0.14608        \n         ordineTU    0.004457 0.06676  -0.25 \nNumber of obs: 2446, groups:  id_subj, 27\n\nDispersion estimate for Gamma family (sigma^2): 0.0291 \n\nConditional model:\n                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)        -0.73956    0.04108 -18.001   &lt;2e-16 ***\nordineTU           -0.04634    0.02085  -2.222   0.0263 *  \ngroupHSAM           0.01122    0.05717   0.196   0.8444    \nordineTU:groupHSAM  0.04476    0.02938   1.523   0.1277    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "analisi_matching.html",
    "href": "analisi_matching.html",
    "title": "HSAM: Analisi Matching Task",
    "section": "",
    "text": "Pre-processing, data cleaning\nHo creato un dataframe con solo trial eseguiti correttamente (accuratezza=1) della condizione matching. Inoltre ho escluso tempi di reazione estremi, definiti come valori oltre ±3 deviazioni standard dalla media per ciascun partecipante e condizione. Con questo criterio sono stati rimosse 16 osservazioni, meno di una per partecipante.\n\n\n\n\n\nCondizione\nMedia_RT\nSD_RT\n\n\n\n\nSCONOSCIUTO\n0.921\n0.223\n\n\nTU\n0.704\n0.175\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdesso fittiamo il modello con le stesse prior usate per la power analisi\n\nformula_brm &lt;- bf(rt ~ identity_label * group + (1 + identity_label | id_subj), family = Gamma(link = \"log\"))\n\npriori &lt;- c(\n  set_prior(\"student_t(3, 0, 1)\", class = \"Intercept\"),\n  set_prior(\"student_t(3, 0, 0.08)\", class = \"b\", coef = \"identity_labelTU\"),\n  set_prior(\"student_t(3, 0, 0.08)\", class = \"b\", coef = \"groupHSAM\"),\n  set_prior(\"student_t(3, 0, 0.08)\", class = \"b\", coef = \"identity_labelTU:groupHSAM\"),\n  set_prior(\"student_t(3, 0, 1)\", class = \"sd\"),\n  set_prior(\"gamma(17,17)\", class = \"shape\")\n)\n\nfit_no_outlier &lt;- brm(\n  formula = formula_brm,\n  data = df_pulito,\n  prior = priori,\n  chains = 4,\n  cores = parallel::detectCores(),\n  iter = 4000,\n  warmup = 1000,\n  seed = 1,\n  control = list(adapt_delta = 0.99)\n)\n\n\n\n Family: gamma \n  Links: mu = log; shape = identity \nFormula: rt ~ identity_label * group + (1 + identity_label | id_subj) \n   Data: df_pulito (Number of observations: 2375) \n  Draws: 4 chains, each with iter = 4000; warmup = 1000; thin = 1;\n         total post-warmup draws = 12000\n\nMultilevel Hyperparameters:\n~id_subj (Number of levels: 28) \n                                Estimate Est.Error l-90% CI u-90% CI Rhat\nsd(Intercept)                       0.12      0.02     0.10     0.16 1.00\nsd(identity_labelTU)                0.12      0.02     0.09     0.16 1.00\ncor(Intercept,identity_labelTU)    -0.22      0.20    -0.54     0.14 1.00\n                                Bulk_ESS Tail_ESS\nsd(Intercept)                       4379     6452\nsd(identity_labelTU)                4252     6797\ncor(Intercept,identity_labelTU)     3809     5009\n\nRegression Coefficients:\n                           Estimate Est.Error l-90% CI u-90% CI Rhat Bulk_ESS\nIntercept                     -0.09      0.03    -0.14    -0.03 1.00     4286\nidentity_labelTU              -0.23      0.03    -0.29    -0.17 1.00     4773\ngroupHSAM                      0.01      0.04    -0.06     0.08 1.00     5160\nidentity_labelTU:groupHSAM    -0.07      0.05    -0.15    -0.00 1.00     5386\n                           Tail_ESS\nIntercept                      6017\nidentity_labelTU               5676\ngroupHSAM                      6461\nidentity_labelTU:groupHSAM     6514\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-90% CI u-90% CI Rhat Bulk_ESS Tail_ESS\nshape    17.97      0.51    17.13    18.82 1.00    16460     9268\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n\n\n\n\n\n\nIl coefficiente β₁ rappresenta la differenza in RT tra stimoli associati al sé (“TU”) e quelli sconosciuti, nel gruppo di controllo (CTRL). L’ intervallo di credibilità al 90% va da –0.29 a –0.17, interamente negativo, evidenziando che i tempi di reazione sono inferiori per gli stimoli associati al sè. Più nel dettaglio, la posterior del parametro è interamente spostata a sinistra dello zero. L’evidenza è molto forte per un self-prioritization effect nei controlli, coerente con la letteratura.\n\n\n\n\n\n\n\n\n\nPer Il coefficiente β3 di interazione l’intervallo di credibilità contiene lo zero. Tuttavia siccome abbiamo la prior del parametro possiamo fare considerazioni aggiuntive che vanno oltre la significatività o non significatività statistica.\n\n\n\n\n\n\n\n\n\nLa probabilità a posteriori che b3 sia positivo:\n\n\n[1] 0.04758333\n\n\nLa probabilità a posteriori che b3 sia nell’area che avevamo definito target ovvero tra 50 e 100ms, (b3 &gt; -0.14 & b3 &lt; -0.07):\n\n\n[1] 0.45125\n\n\nLa probabilità a posteriori che b3 cada nella ROPE, nel Null Intervall di +-10ms, (b3 &gt; -0.013 & b3 &lt; 0.013):\n\n\n[1] 0.05666667\n\n\n\n\n\n\n\n\n\n\n\nHo fatto anche analisi frequentista per vedere se i rislutati convergevano.\n\n\n Family: Gamma  ( log )\nFormula:          rt ~ identity_label * group + (1 + identity_label | id_subj)\nData: df_pulito\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n  -1822.5   -1776.3     919.2   -1838.5      2367 \n\nRandom effects:\n\nConditional model:\n Groups  Name             Variance Std.Dev. Corr  \n id_subj (Intercept)      0.01299  0.1140         \n         identity_labelTU 0.01258  0.1121   -0.26 \nNumber of obs: 2375, groups:  id_subj, 28\n\nDispersion estimate for Gamma family (sigma^2): 0.042 \n\nConditional model:\n                           Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                -0.08826    0.03174  -2.781  0.00542 ** \nidentity_labelTU           -0.23352    0.03228  -7.235 4.67e-13 ***\ngroupHSAM                   0.01191    0.04495   0.265  0.79102    \nidentity_labelTU:groupHSAM -0.08280    0.04574  -1.810  0.07028 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nB1 viene significativo con p=4.67e-13, b3 invece non risulta significativo."
  }
]